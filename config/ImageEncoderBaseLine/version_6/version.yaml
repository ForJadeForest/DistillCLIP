model:
  class_path: DistillModel
  init_args:
    teacher_name: ViT-B/32
    init_type: 'begin'
    download_root: '/data/pyz/.cache'
    loss_control_para:
      loss_name: ['l1', 'cos', 'attn', 'emb', 'hidden']
      loss_scale:
        l1: 1
        emb: 1
        attn: 0.25
        hidden: 0.8
        cos: 1
      percent:
        l1: 0.3
        emb: 0
        attn: 0.2
        hidden: 0.2
        cos: 0.3


trainer:
  logger:
    class_path: pytorch_lightning.loggers.wandb.WandbLogger
    init_args:
      dir: '/data/pyz/result/Dis_CLIP'
      name : 'ImageEncoderBaseLine_l1_cos_attn_hidden_16_init_begin '
      project: 'ImageEncoderDistillation'
      version: null
      log_model: false
      sync_tensorboard: True
  precision: 16