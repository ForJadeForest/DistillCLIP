trainer:
  logger:
    class_path: pytorch_lightning.loggers.wandb.WandbLogger
    init_args:
      dir: '/data/pyz/result/Dis_CLIP'
      name : 'WeightShareDistillation_no-dropout_kl'
      project: 'WeightShareDistillation'
      version: null
      log_model: false
      sync_tensorboard: True

model:
  class_path: DistillModel
  init_args:
    lr: 5.0e-3
    student_encoder:
      class_path: model.weight_share_model.RepeatVisionTransformer
      init_args:
        img_size: 224
        patch_size: 32
        in_chans: 3
        out_dim: 512
        embed_dim: 384
        depth: 4
        num_heads: 12
        mlp_ratio: 4.0
        qkv_bias: True
        drop_rate: 0
        attn_drop_rate: 0
        drop_path_rate: 0
        use_cls_token: True
        repeated_times: 2
        use_transform: True
    loss_control_para:
      loss_name: [ 'l1', 'cos', 'kl' ]
      temperature: 1

