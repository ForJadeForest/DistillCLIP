model:
  class_path: MultiTeacherDistillModule
  init_args:
    image_student:
      class_path: model.component.weight_share_model.RepeatVisionTransformer
      init_args:
        img_size: 224
        patch_size: 32
        in_chans: 3
        out_dim: 512
        embed_dim: 768
        depth: 6
        num_heads: 24
        mlp_ratio: 4.0
        qkv_bias: True
        repeated_times: 2
        use_transform: True
    text_student:
      class_path: model.component.weight_share_model.RepeatTextTransformer
      init_args:
        depth: 4
        embed_dim: 768
        repeated_times: 2
        use_transform: True
    teacher_load_args_list:
      blip:
        name: 'blip_feature_extractor'
        model_type: 'base'
        is_eval: True
      clip:
        name: 'clip'
        model_type: 'ViT-B-32'
        is_eval: True
    gather_feature: True

    load_path:
      image: '/data/share/pyz/final/image/ws_no_smd/174-val_acc0.243-loss0.13381.ckpt'
      text: '/data/share/pyz/final/text/ws_text_no_smd/131-val_acc0.300-loss0.03917.ckpt'


    loss_control_para:
      loss_calculator_args:
        clip:
          t_learnable: True
          loss_name: [ 'soft_label', 'SR' ]
          need_norm: False
          loss_scale:
            soft_label: 0.1
            SR: 1
        blip:
          t_learnable: True
          loss_name: [ 'soft_label', 'SR' ]
          loss_scale:
            soft_label: 0.1
            SR: 0.1
          need_norm: False
      weight_method: "mean"

    warm_steps: 5600
    total_steps: 560000
    weight_decay: 1.0e-3
    lr: 1e-3

    validation_method:
      mscoco_val:
        class_path: MscocoValAccuracy
      flickr8k_val:
        class_path: Flickr8kHumanRating


data:
  class_path: IterableDataModule
  init_args:
    dataset_para:
      cc3m_shards: /data/share/pyz/data/cc/train_cc3m/{00000..00331}.tar
      batch_size: 512
      num_workers: 0
      need_text_processor: False

    dataset_file: cc3m_webdataset
    function_name: get_cc3m_dataset
    val_dataset_init_args:
      mscoco_val:
        is_train: False
        dataset_file: ms_coco
        dataset_name: COCODataset
        dataset_args:
          need_type: 'all'
          root_path: '/data/share/pyz/data/mscoco/'
          annotation_path: '/data/share/pyz/data/mscoco/annotations'
          need_text_processor: False

      flickr8k_val:
        is_train: False
        dataset_file: flickr8k_dataset
        dataset_name: Flickr8kDataset
        dataset_args:
          image_directory: '/data/share/pyz/data/flickr8k'
          input_json_path: '/data/share/pyz/data/flickr8k/flickr8k.json'
          need_text_processor: False

    val_batch_size: 512
    val_num_workers: 0



trainer:
  num_sanity_val_steps: 0
#  detect_anomaly: True
#  strategy: 'ddp'
  default_root_dir: '/data/pyz/result/MultiTeacher'
  accumulate_grad_batches: 1
  accelerator: 'gpu'
  max_epochs: 200
  log_every_n_steps: 50
  enable_progress_bar: True
  check_val_every_n_epoch: 1
#  precision: bf16
  precision: 16
  logger:
    class_path: pytorch_lightning.loggers.wandb.WandbLogger
    init_args:
      save_dir: '/data/pyz/result/MultiTeacher'
      name: 'cc3m-baseline'
      project: 'MultiTeacherDistillation'
      log_model: false
      group: clip


  callbacks:
    - class_path: LearningRateMonitor
      init_args:
        logging_interval: step
    - class_path: ModelSummary
      init_args:
        max_depth: 2
    - class_path: ModelCheckpoint
      init_args:
        filename: 'max-CLIPScore{epoch}-CLIPScore{val-student/clip_score-human_rating-tau_c:.3f}-loss{val-student/ref_clip_score-human_rating-tau_c:.3f}-i2t_acc{val-student/i2t-acc_top-1:.3f}-t2i_acc{val-student/t2i-acc_top-1:.3f}'
        monitor: 'val-student/clip_score-human_rating-tau_c'
        save_last: True
        save_top_k: 2
        mode: 'max'
        auto_insert_metric_name: false
    - class_path: ModelCheckpoint
      init_args:
        filename: 'max-RefCLIPScore-{epoch}-CLIPScore{val-student/clip_score-human_rating-tau_c:.3f}-RefCLIPScore{val-student/ref_clip_score-human_rating-tau_c:.3f}-i2t_acc{val-student/i2t-acc_top-1:.3f}-t2i_acc{val-student/t2i-acc_top-1:.3f}'
        monitor: 'val-student/ref_clip_score-human_rating-tau_c'
        save_last: True
        save_top_k: 2
        mode: 'max'
        auto_insert_metric_name: false
    - class_path: ModelCheckpoint
      init_args:
        filename: 'max-i2t_acc-{epoch}-CLIPScore{val-student/clip_score-human_rating-tau_c:.3f}-RefCLIPScore{val-student/ref_clip_score-human_rating-tau_c:.3f}-i2t_acc{val-student/i2t-acc_top-1:.3f}-t2i_acc{val-student/t2i-acc_top-1:.3f}'
        monitor: 'val-student/i2t-acc_top-1'
        save_last: True
        save_top_k: 2
        mode: 'max'
        auto_insert_metric_name: false
    - class_path: ModelCheckpoint
      init_args:
        filename: 'max-t2i_acc-{epoch}-CLIPScore{val-student/clip_score-human_rating-tau_c:.3f}-RefCLIPScore{val-student/ref_clip_score-human_rating-tau_c:.3f}-i2t_acc{val-student/i2t-acc_top-1:.3f}-t2i_acc{val-student/t2i-acc_top-1:.3f}'
        monitor: 'val-student/t2i-acc_top-1'
        save_last: True
        save_top_k: 2
        mode: 'max'
        auto_insert_metric_name: false
