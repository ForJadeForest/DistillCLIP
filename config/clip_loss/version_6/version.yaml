model:
  class_path: DualDistillModel
  init_args:
    freeze_embed: true
    loss_control_para:
      loss_name: [ 'out_l1', 'out_cos', 'smd', 'fine_grain' ]
      loss_scale:
        smd: 0.02
        fine_grain: 0.1
    norm: false
    lr: 5.0e-3

data:
  class_path: MainDataModule
  init_args:
    dataset: 'ms_coco'
    dataset_name: 'COCODataset'
    dataset_para:
      root_path: '/home/pyz/data_tmp/mscoco'
      annotation_path: '/home/pyz/data_tmp/mscoco/annotations'
    train_batch_size: 1000
    val_batch_size: 1250
    num_workers: 6

trainer:
  logger:
    class_path: pytorch_lightning.loggers.wandb.WandbLogger
    init_args:
      dir: '/data/pyz/result/dis_clip'
      name: 'fine-grain-loss'
      project: 'CLIPDistillation'
      log_model: false
      group: weight_share
      tags: [ 'clip', 'freeze_embed', 'loss_change', 'fine-grain' ]