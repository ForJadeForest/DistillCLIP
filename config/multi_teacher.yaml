model:
  class_path: MultiTeacherDistillModule
  init_args:
    image_student:
      class_path: model.component.weight_share_model.RepeatVisionTransformer
      init_args:
        img_size: 224
        patch_size: 32
        in_chans: 3
        out_dim: 512
        embed_dim: 768
        depth: 6
        num_heads: 24
        mlp_ratio: 4.0
        qkv_bias: True
        repeated_times: 2
        use_transform: True
    text_student:
      class_path: model.component.weight_share_model.RepeatTextTransformer
      init_args:
        depth: 4
        repeated_times: 2
        use_transform: True
    teacher_load_args_list:
      blip:
        name: 'blip_feature_extractor'
        model_type: 'base'
        is_eval: True
      clip:
        name: 'clip'
        model_type: 'ViT-B-32'
        is_eval: True

#    load_path:
#      image: '/data/share/pyz/Dis_CLIP/final/image/wp_single/174-val_acc0.243-loss0.13381.ckpt'
#      text: '/data/share/pyz/Dis_CLIP/final/text/wp_single/131-val_acc0.300-loss0.03917.ckpt'


    loss_control_para:
      loss_name: [ 'hard_label', 'soft_label' ]
      temperature: 0.05

    warm_steps: 15
    total_steps: 300
    weight_decay: 1.0e-3
    lr: 1.0e-4
    validation_method:
      mscoco_val:
        class_path: MscocoValAccuracy
      flickr8k_val:
        class_path: Flickr8kHumanRating

data:
  class_path: IterableDataModule
  init_args:
    dataset_para:
      num_workers: 16
      cc3m_shards: /data/pyz/data/cc/train_cc3m/{00000..00331}.tar
      need_text_processor: False
      batch_size: 512

    dataset_file: cc3m_train_dataset
    function_name: get_cc3m_dataset

    val_dataset_init_args:
      mscoco_val:
        is_train: False
        dataset_file: ms_coco
        dataset_name: COCODataset
        dataset_args:
          need_type: 'all'
          root_path: '/home/pyz32/data_tmp/mscoco/'
          annotation_path: '/home/pyz32/data_tmp/mscoco/annotations'
          need_text_processor: False
      flickr8k_val:
        is_train: False
        dataset_file: flickr8k_dataset
        dataset_name: Flickr8kDataset
        dataset_args:
          image_directory: '/data/pyz/data/flickr8k'
          input_json_path: '/data/pyz/data/flickr8k/flickr8k.json'
          need_text_processor: False
    val_batch_size: 1250
    val_num_workers: 16



trainer:
  num_sanity_val_steps: 0
  strategy: 'ddp'
  limit_train_batches: 3
  default_root_dir: '/data/pyz/result/MultiTeacher'
  accumulate_grad_batches: 1
  accelerator: 'gpu'
  max_epochs: 300
  log_every_n_steps: 15
  enable_progress_bar: True
  check_val_every_n_epoch: 1
  precision: 16
  logger:
    class_path: pytorch_lightning.loggers.wandb.WandbLogger
    init_args:
      save_dir: '/data/pyz/result/MultiTeacher'
      name: 'Test'
      project: 'MultiTeacher'
      log_model: false
      group: clip
      tags: [ 'weight share', 'loss change', 'CLIP model' ]


  callbacks:
    - class_path: LearningRateMonitor
    - class_path: ModelSummary
      init_args:
        max_depth: 2
    - class_path: ModelCheckpoint
      init_args:
        filename: 'max-CLIPScore{epoch}-CLIPScore{val/student-clip_score-human_rating-tau_c:.3f}-loss{val/student-ref_clip_score-human_rating-tau_c:.3f}-i2t_acc{val/student-i2t-acc_top-1:.3f}-t2i_acc{val/student-t2i-acc_top-1:.3f}'
        monitor: 'val/student-clip_score-human_rating-tau_c'
        save_last: True
        save_top_k: 2
        mode: 'max'
        auto_insert_metric_name: false
    - class_path: ModelCheckpoint
      init_args:
        filename: 'max-RefCLIPScore-{epoch}-CLIPScore{val/student-clip_score-human_rating-tau_c:.3f}-RefCLIPScore{val/student-ref_clip_score-human_rating-tau_c:.3f}-i2t_acc{val/student-i2t-acc_top-1:.3f}-t2i_acc{val/student-t2i-acc_top-1:.3f}'
        monitor: 'val/student-ref_clip_score-human_rating-tau_c'
        save_last: True
        save_top_k: 2
        mode: 'max'
        auto_insert_metric_name: false
    - class_path: ModelCheckpoint
      init_args:
        filename: 'max-i2t_acc-{epoch}-CLIPScore{val/student-clip_score-human_rating-tau_c:.3f}-RefCLIPScore{val/student-ref_clip_score-human_rating-tau_c:.3f}-i2t_acc{val/student-i2t-acc_top-1:.3f}-t2i_acc{val/student-t2i-acc_top-1:.3f}'
        monitor: 'val/student-i2t-acc_top-1'
        save_last: True
        save_top_k: 2
        mode: 'max'
        auto_insert_metric_name: false
    - class_path: ModelCheckpoint
      init_args:
        filename: 'max-t2i_acc-{epoch}-CLIPScore{val/student-clip_score-human_rating-tau_c:.3f}-RefCLIPScore{val/student-ref_clip_score-human_rating-tau_c:.3f}-i2t_acc{val/student-i2t-acc_top-1:.3f}-t2i_acc{val/student-t2i-acc_top-1:.3f}'
        monitor: 'val/student-t2i-acc_top-1'
        save_last: True
        save_top_k: 2
        mode: 'max'
        auto_insert_metric_name: false
    - class_path: IterableDatasetProgressBar
      init_args:
        total_length: 2848
