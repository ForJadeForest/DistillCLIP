model:
  class_path: DualDistillModel
  init_args:
    freeze_prefix: [ 'text_encoder' ]
    loss_control_para:
      loss_name: [ 'out_l1', 'out_cos', 'cos_diff' ]
      loss_scale:
        cos_diff: 1
    load_path:
      image: '/data/share/pyz/Dis_CLIP/final/image/ws_no_smd/174-val_acc0.243-loss0.13381.ckpt'
      text: '/data/share/pyz/Dis_CLIP/final/text/compression/201-val_acc0.299-loss0.04052.ckpt'
    text_student:
      class_path: model.component.weight_share_model.RepeatTextTransformer
      init_args:
        depth: 4
        repeated_times: 2
        use_transform: True
        compression_embedding: True
        embedding_compression_dim: 256


trainer:
  logger:
    class_path: pytorch_lightning.loggers.wandb.WandbLogger
    init_args:
      dir: '/data/pyz/result/Dis_CLIP'
      name: 'clip_freeze_text_compression_encoder'
      project: 'CLIPDistillation'
      log_model: false
      group: clip
      tags: [ 'weight share', 'loss change', 'CLIP model' ]