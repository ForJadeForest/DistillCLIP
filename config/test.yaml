model:
  class_path: DualDistillModel
  init_args:
    image_student:
      class_path: model.component.weight_share_model.RepeatVisionTransformer
      init_args:
        img_size: 224
        patch_size: 32
        in_chans: 3
        out_dim: 512
        embed_dim: 768
        depth: 4
        num_heads: 24
        mlp_ratio: 4.0
        qkv_bias: True
        repeated_times: 2
        use_transform: True
    text_student:
      class_path: model.component.weight_share_model.RepeatTextTransformer
      init_args:
        depth: 4
        repeated_times: 2
        use_transform: True
    freeze_embed: False
    norm: False
    loss_control_para:
      loss_name: [ 'out_l1', 'out_cos' ]
    teacher_name: ViT-B/32
    download_root: '/data/pyz/.cache'
    teacher_need_layers: [ 0, 1, 10, 11 ]
    warm_steps: 15
    total_steps: 500
    weight_decay: 1.0e-2
    lr: 5.0e-3
    validation_method:
      mscoco_val:
        class_path: MscocoValAccuracy
      flickr8k_val:
        class_path: Flickr8kHumanRating

data:
  class_path: MultiDataloaderMainDataModule
  init_args:
    init_dataset_args:
#      imagenet:
#        is_train: True
#        dataset_file: imagenet
#        dataset_name: ImageNetDataset
#        dataset_args:
#          data_path: '/data/share/pyz/data/imagenet1k'
      mscoco:
        is_train: True
        dataset_file: ms_coco
        dataset_name: COCODataset
        dataset_args:
          need_type: 'all'
          root_path: '/data/pyz/data/mscoco/'
          annotation_path: '/data/pyz/data/mscoco/annotations'
      mscoco_val:
        is_train: False
        dataset_file: ms_coco
        dataset_name: COCODataset
        dataset_args:
          need_type: 'all'
          root_path: '/data/pyz/data/mscoco/'
          annotation_path: '/data/pyz/data/mscoco/annotations'
      flickr8k_val:
        is_train: False
        dataset_file: flickr8k_dataset
        dataset_name: Flickr8kDataset
        dataset_args:
          image_directory: '/data/pyz/data/flickr8k'
          input_json_path: '/data/pyz/data/flickr8k/flickr8k.json'

    train_batch_size: 512
    val_batch_size: 1250
    num_workers: 16


trainer:
  num_sanity_val_steps: 0
  strategy: 'ddp_find_unused_parameters_false'
  default_root_dir: '/data/pyz/result/dis_clip'
  accumulate_grad_batches: 1
  accelerator: 'gpu'
  limit_train_batches: 16
  #  gradient_clip_val: 10
  max_epochs: 500
  log_every_n_steps: 30
  enable_progress_bar: True
  check_val_every_n_epoch: 1
  precision: 16
  logger:
    class_path: pytorch_lightning.loggers.wandb.WandbLogger
    init_args:
      dir: '/data/pyz/result/Dis_CLIP'
      name: 'cc3m'
      project: 'L-CLIP'
      log_model: false
      group: test

  callbacks:
    - class_path: LearningRateMonitor

    - class_path: ModelSummary
      init_args:
        max_depth: 2
#    - class_path: ModelCheckpoint
#      init_args:
#        filename: '{epoch}-val_acc{val_stu_acc/stu_acc_top1:.3f}-loss{val_loss/loss:.5f}'
#        monitor: 'val_stu_acc/stu_acc_top1'
#        save_last: True
#        save_top_k: 2
#        mode: 'max'
#        auto_insert_metric_name: false
#    - class_path: ModelCheckpoint
#      init_args:
#        filename: '{epoch}-val_acc{val_stu_acc/stu_acc_top1:.3f}-loss{val_loss/loss:.5f}'
#        monitor: 'val_loss/loss'
#        save_last: True
#        save_top_k: 2
#        mode: 'min'
#        auto_insert_metric_name: false