model:
  class_path: DistillModel
  init_args:
    student_encoder:
      class_path: model._text_encoder.TextEncoder
      init_args:
        transformer_width: 256
        transformer_layers: 4
        transformer_heads: 8
        context_length: 77
        vocab_size: 49408
        embed_dim: 512
        tea_transformer_width: 512
        is_student: True
    teacher_name: ViT-B/32
    download_root: '/data/pyz/.cache'
    loss_control_para:
      loss_name: [ 'l1', 'kl', 'cos', 'attn', 'hidden', 'emb' ]
      temperature: 2
      loss_scale:
        l1: 10
        emb: 2.5
        attn: 1.5
        hidden: 20
        cos: 10
        kl: 50
      percent:
        l1: 0.2
        emb: 0.05
        attn: 0.2
        hidden: 0.05
        cos: 0.2
        kl: 0.3
    model_type: 'text'
    map_type: 'begin'

data:
  class_path: DistillationDataModule
  init_args:
    num_workers: 8
    dataset: 'test_dataset'
    batch_size: 32
    dataset_list:
      - class_path: data._coco_dataset.COCODataset
        init_args:
          data_dir: '/data/pyz/data/COCO/'
          cache_dir: '/data/pyz/data/cache3'
          data_type: 'text'
      - class_path: data._conceptual_captions.ConceptualCaptions
        init_args:
          data_dir: '/data/pyz/data/CC'
          cache_dir: '/data/pyz/.cache'
          data_type: 'text'
    kwargs:
      dataset_name: 'CombineDataset'


trainer:
  auto_select_gpus: True
  accelerator: 'gpu'
  devices: [3]

  accumulate_grad_batches: 1
  max_epochs: 50
  min_epochs: 3
  max_steps: -1
  precision: 16
#  log
  log_every_n_steps: 100
  logger:
    class_path: pytorch_lightning.loggers.tensorboard.TensorBoardLogger
    init_args:
      save_dir: '/data/pyz/res'
      name: 'TextEncoder_test'
      version: null
  enable_progress_bar: True
  check_val_every_n_epoch: 1
#  callbacks:
  callbacks:
    - class_path: LearningRateMonitor
    - class_path: ModelSummary
      init_args:
        max_depth: 2
    - class_path: ModelCheckpoint
      init_args:
        filename: '{epoch}-val_acc{hp_metric/stu_acc_top1:.2f}-loss{val/loss}'
        monitor: 'hp_metric/stu_acc_top1'
        save_last: True
        save_top_k: 2
        mode: 'max'
        auto_insert_metric_name: false
    - class_path: EarlyStopping
      init_args:
        monitor: 'val/loss'
        patience: 5
  auto_lr_find: True
#  auto_scale_batch_size: 'binsearch'
#  amp_backend: 'apex'  # or native
#  resume_from_checkpoint: '/load/my/checkpoint'
#  strategy: 'ddp'
#  Debug
  limit_train_batches: 0.01
  limit_val_batches: 0.25 # or int 3 means 3 batches
#  limit_test_batches:
#  fast_dev_run: True
#  limit_predict_batches
#  overfit_batches: 1 # Overfit a fracion of training/validation data (float) or a set number of batches (int). Default: 0.0.t



optimizer:
  class_path: Adam
  init_args:
    lr: 0.00012
    weight_decay: 0.0001

lr_scheduler:
  class_path: CosineAnnealingLR
  init_args:
    T_max: 20