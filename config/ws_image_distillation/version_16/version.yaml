model:
  class_path: DistillModel
  init_args:
    loss_control_para:
      loss_name: [ 'out_l1', 'out_cos', 'out_kl' ]
      loss_scale:
        out_kl: 0.1
      temperature: 5

trainer:
  logger:
    class_path: pytorch_lightning.loggers.wandb.WandbLogger
    init_args:
      dir: '/data/pyz/result/dis_clip'
      name: 'ws-kl_loss-t5'
      project: 'CLIPDistillation'
      log_model: false
      group: ws_image_encoder
      tags: [ 'ws_image_encoder', 'loss change' ]