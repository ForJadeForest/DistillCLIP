model:
  class_path: DistillModel
  init_args:
    student_encoder:
      class_path: model.component.weight_share_model.RepeatVisionTransformer
      init_args:
        img_size: 224
        patch_size: 32
        in_chans: 3
        out_dim: 512
        embed_dim: 768
        depth: 6
        num_heads: 24
        mlp_ratio: 4.0
        qkv_bias: True
        qk_scale: null
        drop_rate: 0.
        attn_drop_rate: 0.
        drop_path_rate: 0.
        hybrid_backbone: null
        rpe_config: null
        repeated_times: 2
        use_transform: True
    freeze_embed: true

trainer:
  logger:
    class_path: pytorch_lightning.loggers.wandb.WandbLogger
    init_args:
      dir: '/data/pyz/result/dis_clip'
      name: 'ws_image_baseline'
      project: 'CLIPDistillation'
      log_model: false
      group: ws_image_encoder
      tags: [ 'ws_image_encoder', 'model change' , 'final']

data:
  class_path: MainDataModule
  init_args:
    num_workers: 6
    dataset: 'combine_image_dataset'
    dataset_name: 'CombineImageDataset'
    train_batch_size: 1024
    val_batch_size: 1250
    prepare_para:
      overwrite: False
      raw_data_dir: '/home/pyz32/data_tmp'
    dataset_para:
      cache_dir: '/data/pyz/.cache'
      combine_dataset_path: '/home/pyz32/data_tmp/combine_dataset/'
      image_use: [ 'imagenet' ]
      teacher_name: 'ViT-B/32'